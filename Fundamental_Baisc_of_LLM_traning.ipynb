{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOA4ve6bx1LLEZsuD5ZMRFJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dileep9968/mastery-in-llm/blob/main/Fundamental_Baisc_of_LLM_traning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aD8AKhwDndZz"
      },
      "outputs": [],
      "source": [
        "#!pip install torch==2.4.0\n",
        "#!pip install torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "id": "HBE1_XWin6R3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e 'git+https://github.com/axolotl-ai-cloud/axolotl.git@78b42a3fe13c49e317bc116b9999c30e070322cc#egg=axolotl' # ensures the same version we used in the course"
      ],
      "metadata": {
        "id": "kpwHFuuroBKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#configuration setup\n",
        "import yaml\n",
        "train_config = \"\"\"\n",
        "# model params\n",
        "base_model: TinyLlama/TinyLlama-1.1B-Chat-v1.0\n",
        "model_type: LlamaForCausalLM\n",
        "tokenizer_type: LlaaTokenizer\n",
        "\n",
        "# dataset params\n",
        "datasets:\n",
        "  - path: jaydenccc/AI_Storyteller_Dataset\n",
        "    type:\n",
        "      system_prompt: \"\"\n",
        "      field_system: system\n",
        "      field_instruction: synopsis\n",
        "      field_output: short_story\n",
        "      format: \"<|user|>\\n {instruction} </s>\\n<|assistant|>\"\n",
        "      no_input_format: \"<|user|> {instruction} </s>\\n<|assistant|>\"\n",
        "\n",
        "output_dir: ./models/TinyLlama_Storyteller\n",
        "\n",
        "# model params\n",
        "sequence_lenght: 1024\n",
        "bf16: auto\n",
        "tf32: false\n",
        "\n",
        "# traning params\n",
        "batch_size: 4\n",
        "micro_batch_size: 4\n",
        "num_epochs: 2\n",
        "optimizer: adamw_bnb_8bit\n",
        "learning_rate: 0.0002\n",
        "\n",
        "logging_steps: 1\n",
        "\"\"\"\n",
        "\n",
        "# converting the yaml file to python dicionary\n",
        "yaml_dict = yaml.safe_load(train_config)\n",
        "yaml_dict"
      ],
      "metadata": {
        "id": "4hXrDGwKoKl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the YAML file\n",
        "with open('basic_train.yaml', 'w') as file:\n",
        "  yaml.dump(yaml_dict, file)"
      ],
      "metadata": {
        "id": "1jhnK1-7owtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training launch\n",
        "!accelerate launch -m axolotl.cli.train basic_train.yaml"
      ],
      "metadata": {
        "id": "YTj6ZGXOqguH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9FJC6qt7suFI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}